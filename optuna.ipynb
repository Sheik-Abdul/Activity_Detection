{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKQhrDizTfu-",
        "outputId": "c4440e3a-9779-4cab-a436-de1c4fea10c0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.2.0-py3-none-any.whl (390 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.9.1 (from optuna)\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.11.1 cmaes-0.9.1 colorlog-6.7.0 optuna-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMUt9w7OPtLc",
        "outputId": "291acb7c-e28d-4a21-f186-c2cf5263776a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-21 21:32:24,337] A new study created in memory with name: no-name-57793e90-ed7f-4561-b7b6-28f62f756e04\n",
            "[I 2023-06-21 21:32:24,357] Trial 0 finished with value: 0.12447257383966248 and parameters: {'model_type': 'decision_tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 3, 'min_weight_fraction_leaf': 0.0, 'min_impurity_decrease': 0.0, 'ccp_alpha': 0.0}. Best is trial 0 with value: 0.12447257383966248.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-21 21:32:41,268] Trial 1 finished with value: 0.03586497890295359 and parameters: {'model_type': 'lstm', 'units': 32, 'dropout_rate_lstm': 0.2, 'optimizer_lstm': 'adam', 'activation_lstm': 'tanh', 'recurrent_activation': 'tanh', 'bias_initializer': 'ones', 'kernel_initializer': 'orthogonal', 'recurrent_initializer': 'glorot_uniform', 'return_sequences': False, 'stateful': True, 'batch_size': 32}. Best is trial 1 with value: 0.03586497890295359.\n",
            "<ipython-input-3-ba7670258aba>:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-21 21:32:50,804] Trial 2 finished with value: 0.14135021097046419 and parameters: {'model_type': 'cnn', 'filters': 16, 'kernel_size': 7, 'activation': 'sigmoid', 'optimizer': 'adam', 'pooling': 'max', 'dropout_rate': 0.0865430013783719, 'dense_units': 256}. Best is trial 1 with value: 0.03586497890295359.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-21 21:33:07,859] Trial 3 finished with value: 0.05485232067510548 and parameters: {'model_type': 'lstm', 'units': 64, 'dropout_rate_lstm': 0.2, 'optimizer_lstm': 'rmsprop', 'activation_lstm': 'tanh', 'recurrent_activation': 'sigmoid', 'bias_initializer': 'zeros', 'kernel_initializer': 'glorot_uniform', 'recurrent_initializer': 'glorot_uniform', 'return_sequences': False, 'stateful': True, 'batch_size': 64}. Best is trial 1 with value: 0.03586497890295359.\n",
            "[I 2023-06-21 21:33:09,022] Trial 4 finished with value: 0.069620253164557 and parameters: {'model_type': 'random_forest', 'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'min_impurity_decrease': 0.0, 'ccp_alpha': 0.0, 'max_samples': 0.5}. Best is trial 1 with value: 0.03586497890295359.\n",
            "[I 2023-06-21 21:33:09,452] Trial 5 finished with value: 0.23206751054852326 and parameters: {'model_type': 'random_forest', 'n_estimators': 100, 'criterion': 'log_loss', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'min_impurity_decrease': 0.0, 'ccp_alpha': 0.1, 'max_samples': 0.8}. Best is trial 1 with value: 0.03586497890295359.\n",
            "<ipython-input-3-ba7670258aba>:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-21 21:33:13,527] Trial 6 finished with value: 0.10126582278481011 and parameters: {'model_type': 'cnn', 'filters': 32, 'kernel_size': 5, 'activation': 'relu', 'optimizer': 'adam', 'pooling': 'max', 'dropout_rate': 0.42607429770569455, 'dense_units': 64}. Best is trial 1 with value: 0.03586497890295359.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-21 21:33:30,402] Trial 7 finished with value: 0.04008438818565396 and parameters: {'model_type': 'lstm', 'units': 64, 'dropout_rate_lstm': 0.2, 'optimizer_lstm': 'adam', 'activation_lstm': 'tanh', 'recurrent_activation': 'sigmoid', 'bias_initializer': 'zeros', 'kernel_initializer': 'orthogonal', 'recurrent_initializer': 'orthogonal', 'return_sequences': False, 'stateful': False, 'batch_size': 64}. Best is trial 1 with value: 0.03586497890295359.\n",
            "<ipython-input-3-ba7670258aba>:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-21 21:33:42,252] Trial 8 finished with value: 0.12869198312236285 and parameters: {'model_type': 'cnn', 'filters': 32, 'kernel_size': 5, 'activation': 'sigmoid', 'optimizer': 'adam', 'pooling': 'max', 'dropout_rate': 0.23711321465547852, 'dense_units': 128}. Best is trial 1 with value: 0.03586497890295359.\n",
            "[I 2023-06-21 21:33:43,599] Trial 9 finished with value: 1.0 and parameters: {'model_type': 'random_forest', 'n_estimators': 600, 'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 6, 'min_weight_fraction_leaf': 0.2, 'min_impurity_decrease': 0.0, 'ccp_alpha': 0.1, 'max_samples': 0.5}. Best is trial 1 with value: 0.03586497890295359.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-21 21:33:53,968] Trial 10 finished with value: 0.048523206751054815 and parameters: {'model_type': 'lstm', 'units': 32, 'dropout_rate_lstm': 0.5, 'optimizer_lstm': 'adam', 'activation_lstm': 'relu', 'recurrent_activation': 'tanh', 'bias_initializer': 'ones', 'kernel_initializer': 'orthogonal', 'recurrent_initializer': 'glorot_uniform', 'return_sequences': True, 'stateful': True, 'batch_size': 32}. Best is trial 1 with value: 0.03586497890295359.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-21 21:34:01,988] Trial 11 finished with value: 0.052742616033755296 and parameters: {'model_type': 'lstm', 'units': 32, 'dropout_rate_lstm': 0.2, 'optimizer_lstm': 'adam', 'activation_lstm': 'tanh', 'recurrent_activation': 'tanh', 'bias_initializer': 'zeros', 'kernel_initializer': 'orthogonal', 'recurrent_initializer': 'orthogonal', 'return_sequences': False, 'stateful': False, 'batch_size': 32}. Best is trial 1 with value: 0.03586497890295359.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-21 21:34:20,096] Trial 12 finished with value: 0.04641350210970463 and parameters: {'model_type': 'lstm', 'units': 64, 'dropout_rate_lstm': 0.2, 'optimizer_lstm': 'adam', 'activation_lstm': 'tanh', 'recurrent_activation': 'sigmoid', 'bias_initializer': 'ones', 'kernel_initializer': 'orthogonal', 'recurrent_initializer': 'orthogonal', 'return_sequences': False, 'stateful': False, 'batch_size': 64}. Best is trial 1 with value: 0.03586497890295359.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-21 21:34:38,172] Trial 13 finished with value: 0.048523206751054815 and parameters: {'model_type': 'lstm', 'units': 128, 'dropout_rate_lstm': 0.2, 'optimizer_lstm': 'adam', 'activation_lstm': 'tanh', 'recurrent_activation': 'sigmoid', 'bias_initializer': 'zeros', 'kernel_initializer': 'orthogonal', 'recurrent_initializer': 'orthogonal', 'return_sequences': False, 'stateful': False, 'batch_size': 32}. Best is trial 1 with value: 0.03586497890295359.\n",
            "[I 2023-06-21 21:34:38,196] Trial 14 finished with value: 1.0 and parameters: {'model_type': 'decision_tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.2, 'min_impurity_decrease': 0.2, 'ccp_alpha': 0.2}. Best is trial 1 with value: 0.03586497890295359.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-21 21:34:53,705] Trial 15 finished with value: 0.044303797468354444 and parameters: {'model_type': 'lstm', 'units': 64, 'dropout_rate_lstm': 0.2, 'optimizer_lstm': 'adam', 'activation_lstm': 'tanh', 'recurrent_activation': 'tanh', 'bias_initializer': 'ones', 'kernel_initializer': 'orthogonal', 'recurrent_initializer': 'glorot_uniform', 'return_sequences': False, 'stateful': True, 'batch_size': 64}. Best is trial 1 with value: 0.03586497890295359.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, AveragePooling1D, Flatten, Bidirectional\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "import optuna\n",
        "from optuna.trial import Trial\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/user01_.csv\")\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Preprocess the data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "encoder = OneHotEncoder(categories='auto')\n",
        "y = encoder.fit_transform(y.reshape(-1, 1)).toarray()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Reshape the input data to match the expected input shape of the CNN\n",
        "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Reshape the input data to match the expected input shape of the LSTM\n",
        "X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Define the LSTM model with different activation functions\n",
        "def create_lstm_model(trial):\n",
        "    units = trial.suggest_categorical('units', [32, 64, 128])\n",
        "    dropout_rate = trial.suggest_categorical('dropout_rate_lstm', [0.2, 0.5])\n",
        "    optimizer = trial.suggest_categorical('optimizer_lstm', ['adam', 'rmsprop'])\n",
        "    activation = trial.suggest_categorical('activation_lstm', ['relu', 'tanh'])\n",
        "    recurrent_activation = trial.suggest_categorical('recurrent_activation', ['sigmoid', 'tanh'])\n",
        "    bias_initializer = trial.suggest_categorical('bias_initializer', ['zeros', 'ones'])\n",
        "    kernel_initializer = trial.suggest_categorical('kernel_initializer', ['glorot_uniform', 'orthogonal'])\n",
        "    recurrent_initializer = trial.suggest_categorical('recurrent_initializer', ['glorot_uniform', 'orthogonal'])\n",
        "    return_sequences = trial.suggest_categorical('return_sequences', [True, False])\n",
        "    stateful = trial.suggest_categorical('stateful', [True, False])\n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 64])\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(units=units, return_sequences=True, recurrent_activation=recurrent_activation,\n",
        "                                 bias_initializer=bias_initializer, kernel_initializer=kernel_initializer,\n",
        "                                 recurrent_initializer=recurrent_initializer),\n",
        "                            input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Bidirectional(LSTM(units=units, return_sequences=True, recurrent_activation=recurrent_activation,\n",
        "                                 bias_initializer=bias_initializer, kernel_initializer=kernel_initializer,\n",
        "                                 recurrent_initializer=recurrent_initializer)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=64, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(units=y_train.shape[1], activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_cnn_model(trial):\n",
        "    filters = trial.suggest_categorical('filters', [16, 32, 64])\n",
        "    kernel_size = trial.suggest_categorical('kernel_size', [3, 5, 7])\n",
        "    activation = trial.suggest_categorical('activation', ['relu', 'sigmoid'])\n",
        "    optimizer = trial.suggest_categorical('optimizer', ['adam', 'rmsprop'])\n",
        "    pooling = trial.suggest_categorical('pooling', ['max', 'average'])\n",
        "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.5)\n",
        "    dense_units = trial.suggest_categorical('dense_units', [64, 128, 256])\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation=activation,\n",
        "                     input_shape=(X_train.shape[1], 1)))\n",
        "\n",
        "    if pooling == 'max':\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "    elif pooling == 'average':\n",
        "        model.add(AveragePooling1D(pool_size=2))\n",
        "\n",
        "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation=activation))\n",
        "\n",
        "    if pooling == 'max':\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "    elif pooling == 'average':\n",
        "        model.add(AveragePooling1D(pool_size=2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=dense_units, activation=activation))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(units=y_train.shape[1], activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_decision_tree_model(trial):\n",
        "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss'])\n",
        "    splitter = trial.suggest_categorical('splitter', ['best', 'random'])\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
        "    min_weight_fraction_leaf = trial.suggest_categorical('min_weight_fraction_leaf', [0.0, 0.1, 0.2])\n",
        "    min_impurity_decrease = trial.suggest_categorical('min_impurity_decrease', [0.0, 0.1, 0.2])\n",
        "    ccp_alpha = trial.suggest_categorical('ccp_alpha', [0.0, 0.1, 0.2])\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth, min_samples_split=min_samples_split,\n",
        "                                   min_samples_leaf=min_samples_leaf, min_weight_fraction_leaf=min_weight_fraction_leaf, max_features='sqrt',\n",
        "                                   max_leaf_nodes=10, min_impurity_decrease=min_impurity_decrease, ccp_alpha=ccp_alpha)\n",
        "    return model\n",
        "\n",
        "# Define the Random Forest model\n",
        "def create_random_forest_model(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 100, 1000, step=100)\n",
        "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss'])\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
        "    min_weight_fraction_leaf = trial.suggest_categorical('min_weight_fraction_leaf', [0.0, 0.1, 0.2])\n",
        "    min_impurity_decrease = trial.suggest_categorical('min_impurity_decrease', [0.0, 0.1, 0.2])\n",
        "    ccp_alpha = trial.suggest_categorical('ccp_alpha', [0.0, 0.1, 0.2])\n",
        "    max_samples = trial.suggest_categorical('max_samples', [None, 0.5, 0.8])\n",
        "\n",
        "    model = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split,\n",
        "                                   min_samples_leaf=min_samples_leaf, min_weight_fraction_leaf=min_weight_fraction_leaf, max_features='sqrt',\n",
        "                                   max_leaf_nodes=10, min_impurity_decrease=min_impurity_decrease, ccp_alpha=ccp_alpha, max_samples=max_samples)\n",
        "    return model\n",
        "\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "# Define the objective function for Optuna optimization\n",
        "def objective(trial):\n",
        "    model_type = trial.suggest_categorical('model_type', ['lstm', 'cnn', 'decision_tree', 'random_forest'])\n",
        "    if model_type == 'lstm':\n",
        "        model = create_lstm_model(trial)\n",
        "        model.fit(X_train_lstm, y_train,\n",
        "                epochs=100,\n",
        "                batch_size=64,\n",
        "                validation_data=(X_test_lstm, y_test),\n",
        "                callbacks=early_stopping, verbose=0\n",
        "              )\n",
        "        y_pred_lstm = model.predict(X_test_lstm)\n",
        "        y_pred_classes_lstm = np.argmax(y_pred_lstm, axis=1)\n",
        "        accuracy = accuracy_score(y_true_classes, y_pred_classes_lstm)\n",
        "    elif model_type == 'cnn':\n",
        "        model = create_cnn_model(trial)\n",
        "        model.fit(X_train_cnn, y_train,\n",
        "                       epochs=100,\n",
        "                       batch_size=64,\n",
        "                       validation_data=(X_test_cnn, y_test),\n",
        "                       callbacks=early_stopping, verbose=0\n",
        "                      )\n",
        "        y_pred_cnn = model.predict(X_test_cnn)\n",
        "        y_pred_classes_cnn = np.argmax(y_pred_cnn, axis=1)\n",
        "        accuracy = accuracy_score(y_true_classes, y_pred_classes_cnn)\n",
        "    elif model_type == 'decision_tree':\n",
        "        model = create_decision_tree_model(trial)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "    else:\n",
        "        model = create_random_forest_model(trial)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return 1 - accuracy\n",
        "\n",
        "# Perform Bayesian optimization with Optuna\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = study.best_params\n",
        "\n",
        "if best_params['model_type'] == 'lstm':\n",
        "    trial = optuna.trial.FixedTrial(best_params)\n",
        "    model = create_lstm_model(trial)\n",
        "    model.fit(X_train_lstm, y_train,\n",
        "                       epochs=100,\n",
        "                       batch_size=64,\n",
        "                       validation_data=(X_test_lstm, y_test),\n",
        "                       callbacks=early_stopping\n",
        "                      )\n",
        "    y_pred_lstm = model.predict(X_test_lstm)\n",
        "    y_pred_classes_lstm = np.argmax(y_pred_lstm, axis=1)\n",
        "    accuracy = accuracy_score(y_true_classes, y_pred_classes_lstm)\n",
        "    precision = precision_score(y_true_classes, y_pred_classes_lstm, average='weighted',zero_division=1)\n",
        "    recall = recall_score(y_true_classes, y_pred_classes_lstm, average='weighted')\n",
        "    f1 = f1_score(y_true_classes, y_pred_classes_lstm, average='weighted')\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_lstm, average='weighted', multi_class='ovr')\n",
        "    print(\"Evaluation Metrics LSTM:\")\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1)\n",
        "    print(\"ROC AUC:\", roc_auc)\n",
        "elif best_params['model_type'] == 'cnn':\n",
        "    trial = optuna.trial.FixedTrial(best_params)\n",
        "    model = create_cnn_model(trial)\n",
        "    model.fit(X_train_cnn, y_train,\n",
        "                       epochs=100,\n",
        "                       batch_size=64,\n",
        "                       validation_data=(X_test_cnn, y_test),\n",
        "                       callbacks=early_stopping\n",
        "                      )\n",
        "    y_pred_cnn = model.predict(X_test_cnn)\n",
        "    y_pred_classes_cnn = np.argmax(y_pred_cnn, axis=1)\n",
        "    accuracy = accuracy_score(y_true_classes, y_pred_classes_cnn)\n",
        "    precision = precision_score(y_true_classes, y_pred_classes_cnn, average='weighted',zero_division=1)\n",
        "    recall = recall_score(y_true_classes, y_pred_classes_cnn, average='weighted')\n",
        "    f1 = f1_score(y_true_classes, y_pred_classes_cnn, average='weighted')\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_cnn, average='weighted', multi_class='ovr')\n",
        "    print(\"Evaluation Metrics CNN:\")\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1)\n",
        "    print(\"ROC AUC:\", roc_auc)\n",
        "elif best_params['model_type'] == 'decision_tree':\n",
        "    trial = optuna.trial.FixedTrial(best_params)\n",
        "    model = create_decision_tree_model(trial)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted',zero_division=1)\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    roc_auc = roc_auc_score(y_test, y_pred, average='weighted', multi_class='ovr')\n",
        "    print(f\"Evaluation Metrics {best_params['model_type']}:\")\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1)\n",
        "    print(\"ROC AUC:\", roc_auc)\n",
        "else:\n",
        "    trial = optuna.trial.FixedTrial(best_params)\n",
        "    model = create_random_forest_model(trial)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted',zero_division=1)\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    roc_auc = roc_auc_score(y_test, y_pred, average='weighted', multi_class='ovr')\n",
        "    print(f\"Evaluation Metrics {best_params['model_type']}:\")\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1)\n",
        "    print(\"ROC AUC:\", roc_auc)\n"
      ]
    }
  ]
}