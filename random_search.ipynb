{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1OmeXJKTBMJ1aeCjspIhB5NsmBVh1Ye0f",
      "authorship_tag": "ABX9TyOGjXDnqIiQ9Jm1ttW8DJ8M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sheik-Abdul/Activity_Detection/blob/main/random_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqy7jscdM_Hs",
        "outputId": "bba6b320-9298-4c7f-cb55-ffaab377e669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-fda875f4b241>:85: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  'LSTM': KerasClassifier(build_fn=create_lstm_model, epochs=100, batch_size=32, verbose=0),\n",
            "<ipython-input-9-fda875f4b241>:88: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  'CNN': KerasClassifier(build_fn=create_cnn_model, epochs=100, batch_size=32, verbose=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 5s 6ms/step\n",
            "Evaluation Metrics LSTM:\n",
            "Accuracy: 0.9409282700421941\n",
            "Precision: 0.9447048557853209\n",
            "Recall: 0.9409282700421941\n",
            "F1 Score: 0.9419059404891366\n",
            "ROC AUC: 0.9913460404618946\n",
            "LSTM - Best Parameters: {'units': 32, 'stateful': True, 'return_sequences': False, 'recurrent_initializer': 'glorot_uniform', 'recurrent_activation': 'sigmoid', 'kernel_initializer': 'glorot_uniform', 'dropout_rate': 0.0, 'bias_initializer': 'ones', 'batch_size': 32, 'activation': 'relu'}, Accuracy: 0.9409282700421941\n",
            "Evaluation Metrics Decision Tree:\n",
            "Accuracy: 0.9113924050632911\n",
            "Precision: 0.9205015647228085\n",
            "Recall: 0.9113924050632911\n",
            "F1 Score: 0.9134345395476474\n",
            "ROC AUC: 0.9464622111545591\n",
            "Decision Tree - Best Parameters: {'splitter': 'best', 'min_weight_fraction_leaf': 0.0, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': None, 'max_depth': 10, 'criterion': 'log_loss', 'ccp_alpha': 0.0}, Accuracy: 0.9113924050632911\n",
            "Evaluation Metrics Random Forest:\n",
            "Accuracy: 0.7531645569620253\n",
            "Precision: 0.9658775746920452\n",
            "Recall: 0.7531645569620253\n",
            "F1 Score: 0.7907247424359206\n",
            "ROC AUC: 0.8721471837546874\n",
            "Random Forest - Best Parameters: {'n_estimators': 100, 'min_weight_fraction_leaf': 0.1, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.1, 'max_samples': 0.8, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': None, 'criterion': 'entropy', 'ccp_alpha': 0.0}, Accuracy: 0.7531645569620253\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "Evaluation Metrics CNN:\n",
            "Accuracy: 0.919831223628692\n",
            "Precision: 0.9260330150270191\n",
            "Recall: 0.919831223628692\n",
            "F1 Score: 0.921264507559278\n",
            "ROC AUC: 0.988044183811246\n",
            "CNN - Best Parameters: {'validation_split': 0.2, 'strides': 2, 'pooling': 'average', 'pool_size': 2, 'padding': 'valid', 'optimizer': 'adam', 'momentum': 0.9, 'learning_rate': 0.1, 'kernel_size': 5, 'filters': 32, 'epochs': 10, 'dropout_rate': 0.0, 'batch_size': 64, 'activation': 'relu'}, Accuracy: 0.919831223628692\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, AveragePooling1D, Flatten, Bidirectional\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/user01_.csv\")\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Preprocess the data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "encoder = OneHotEncoder(categories='auto')\n",
        "y = encoder.fit_transform(y.reshape(-1, 1)).toarray()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Reshape the input data to match the expected input shape of the CNN\n",
        "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Reshape the input data to match the expected input shape of the LSTM\n",
        "X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Define the LSTM model with different activation functions\n",
        "\n",
        "def create_lstm_model(units=64, dropout_rate=0.2, activation='relu', optimizer='adam',\n",
        "                      recurrent_activation='sigmoid', bias_initializer='zeros',\n",
        "                      kernel_initializer='orthogonal', return_sequences=False,\n",
        "                      stateful=False, batch_size=32, recurrent_initializer='orthogonal'):\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(units=units, return_sequences=True, recurrent_activation=recurrent_activation,\n",
        "                                 bias_initializer=bias_initializer, kernel_initializer=kernel_initializer,\n",
        "                                 recurrent_initializer=recurrent_initializer),\n",
        "                            input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Bidirectional(LSTM(units=units, return_sequences=True, recurrent_activation=recurrent_activation,\n",
        "                                 bias_initializer=bias_initializer, kernel_initializer=kernel_initializer,\n",
        "                                recurrent_initializer=recurrent_initializer)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Bidirectional(LSTM(units=units, recurrent_activation=recurrent_activation,\n",
        "                                 bias_initializer=bias_initializer, kernel_initializer=kernel_initializer,\n",
        "                                recurrent_initializer=recurrent_initializer)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(units=y.shape[1], activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Define the other models (Decision Tree, Random Forest, CNN, etc.)\n",
        "def create_cnn_model(filters=16, kernel_size=3, strides=1, padding='valid', pool_size=2, activation='relu',\n",
        "                     pooling=None, dropout_rate=0.2, optimizer='adam', batch_size=32, epochs=10,\n",
        "                     learning_rate=0.001, momentum=0.9, validation_split=0.1):\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding,\n",
        "                     activation=activation, input_shape=(X_train.shape[1], 1)))\n",
        "    if pooling is not None:\n",
        "        if pooling == 'max':\n",
        "            model.add(MaxPooling1D(pool_size=pool_size))\n",
        "        elif pooling == 'average':\n",
        "            model.add(AveragePooling1D(pool_size=pool_size))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=32, activation=activation))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(units=y.shape[1], activation='softmax'))\n",
        "    optimizer = SGD(learning_rate=learning_rate, momentum=momentum)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create a dictionary of models\n",
        "models = {\n",
        "    'LSTM': KerasClassifier(build_fn=create_lstm_model, epochs=100, batch_size=32, verbose=0),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'CNN': KerasClassifier(build_fn=create_cnn_model, epochs=100, batch_size=32, verbose=0)\n",
        "}\n",
        "\n",
        "# Define the hyperparameters for grid search for each model\n",
        "hyperparameters = {\n",
        "    'LSTM': {\n",
        "        'units': [32, 64, 128],  # Number of units/neurons in the LSTM layer\n",
        "        'activation': ['tanh', 'relu'],  # Activation function\n",
        "        'recurrent_activation': ['sigmoid', 'tanh'],\n",
        "        'kernel_initializer': ['glorot_uniform', 'orthogonal'],  # Weight initializer for the kernel weights matrix\n",
        "        'recurrent_initializer': ['glorot_uniform', 'orthogonal'],  # Weight initializer for the recurrent_kernel weights matrix\n",
        "        'bias_initializer': ['zeros', 'ones'],  # Initializer for the bias vector\n",
        "        'dropout_rate': [0.0, 0.2, 0.5],  # Fraction of units to drop for input transformation\n",
        "        'return_sequences': [True, False],  # Whether to return the full sequence or only the last output\n",
        "        'stateful': [True, False],  # Whether to use the last state as the initial state for the next batch\n",
        "        'batch_size': [32, 64]  # Number of samples per gradient update\n",
        "    },\n",
        "    'Decision Tree': {\n",
        "        'criterion': ['gini', 'entropy', 'log_loss'],\n",
        "        'splitter': ['best', 'random'],\n",
        "        'max_depth': [None, 5, 10],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 5],\n",
        "        'min_weight_fraction_leaf': [0.0, 0.1, 0.2],\n",
        "        'max_features': [None, 'sqrt'],\n",
        "        'max_leaf_nodes': [None, 5, 10],\n",
        "        'min_impurity_decrease': [0.0, 0.1, 0.2],\n",
        "        'ccp_alpha': [0.0, 0.1, 0.2]\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'criterion': ['gini', 'entropy', 'log_loss'],\n",
        "        'max_depth': [None, 5, 10],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 5],\n",
        "        'min_weight_fraction_leaf': [0.0, 0.1, 0.2],\n",
        "        'max_features': ['sqrt', 'log2', None],\n",
        "        'max_leaf_nodes': [None, 10, 20],\n",
        "        'min_impurity_decrease': [0.0, 0.1, 0.2],\n",
        "        'ccp_alpha': [0.0, 0.1, 0.2],\n",
        "        'max_samples': [None, 0.5, 0.8]\n",
        "    },\n",
        "    'CNN': {\n",
        "        'filters': [16, 32, 64],\n",
        "        'kernel_size': [3, 5],\n",
        "        'pool_size': [2, 4, 8],\n",
        "        'strides': [1, 2],\n",
        "        'padding': ['same', 'valid'],\n",
        "        'activation': ['relu', 'sigmoid'],\n",
        "        'pooling': [None, 'max', 'average'],\n",
        "        'dropout_rate': [0.0, 0.25, 0.5],\n",
        "        'optimizer': ['adam', 'rmsprop'],\n",
        "        'batch_size': [32, 64, 128],\n",
        "        'epochs': [10, 20, 30],\n",
        "        'learning_rate': [0.001, 0.01, 0.1],\n",
        "        'momentum': [0.9, 0.95, 0.99],\n",
        "        'validation_split': [0.1, 0.2, 0.3]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Perform grid search for each model\n",
        "best_models = {}\n",
        "for model_name, model in models.items():\n",
        "    params = hyperparameters.get(model_name, {})\n",
        "    random_search = RandomizedSearchCV(estimator=model, param_distributions=params, cv=3, n_iter=10)\n",
        "    if model_name == 'LSTM':\n",
        "        random_search.fit(X_train_lstm, y_train)\n",
        "        best_batch_size_lstm = random_search.best_params_['batch_size']\n",
        "    elif model_name == 'CNN':\n",
        "        random_search.fit(X_train_cnn, y_train)\n",
        "        best_batch_size_cnn = random_search.best_params_['batch_size']\n",
        "    else:\n",
        "        random_search.fit(X_train, y_train)\n",
        "    best_model = random_search.best_estimator_\n",
        "    best_models[model_name] = {\n",
        "        'model': best_model,\n",
        "        'best_params': random_search.best_params_,\n",
        "    }\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "# Evaluate the best models\n",
        "for model_name, model_data in best_models.items():\n",
        "    best_model = model_data['model']\n",
        "    best_params = model_data['best_params']\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "    if model_name == 'LSTM':\n",
        "        best_model.fit(X_train_lstm, y_train,\n",
        "                       epochs=100,\n",
        "                       batch_size=best_batch_size_lstm,\n",
        "                       validation_data=(X_test_lstm, y_test),\n",
        "                       callbacks=early_stopping\n",
        "                      )\n",
        "        y_pred_lstm = best_model.predict_proba(X_test_lstm)\n",
        "        y_pred_classes_lstm = np.argmax(y_pred_lstm, axis=1)\n",
        "        accuracy = accuracy_score(y_true_classes, y_pred_classes_lstm)\n",
        "        precision = precision_score(y_true_classes, y_pred_classes_lstm, average='weighted',zero_division=1)\n",
        "        recall = recall_score(y_true_classes, y_pred_classes_lstm, average='weighted')\n",
        "        f1 = f1_score(y_true_classes, y_pred_classes_lstm, average='weighted')\n",
        "        roc_auc = roc_auc_score(y_test, y_pred_lstm, average='weighted', multi_class='ovr')\n",
        "        print(\"Evaluation Metrics LSTM:\")\n",
        "        print(\"Accuracy:\", accuracy)\n",
        "        print(\"Precision:\", precision)\n",
        "        print(\"Recall:\", recall)\n",
        "        print(\"F1 Score:\", f1)\n",
        "        print(\"ROC AUC:\", roc_auc)\n",
        "    elif model_name == 'CNN':\n",
        "        best_model.fit(X_train_cnn, y_train,\n",
        "                       epochs=100,\n",
        "                       batch_size=best_batch_size_cnn,\n",
        "                       validation_data=(X_test_cnn, y_test),\n",
        "                       callbacks=early_stopping\n",
        "                      )\n",
        "        y_pred_cnn = best_model.predict_proba(X_test_cnn)\n",
        "        y_pred_classes_cnn = np.argmax(y_pred_cnn, axis=1)\n",
        "        accuracy = accuracy_score(y_true_classes, y_pred_classes_cnn)\n",
        "        precision = precision_score(y_true_classes, y_pred_classes_cnn, average='weighted',zero_division=1)\n",
        "        recall = recall_score(y_true_classes, y_pred_classes_cnn, average='weighted')\n",
        "        f1 = f1_score(y_true_classes, y_pred_classes_cnn, average='weighted')\n",
        "        roc_auc = roc_auc_score(y_test, y_pred_cnn, average='weighted', multi_class='ovr')\n",
        "        print(\"Evaluation Metrics CNN:\")\n",
        "        print(\"Accuracy:\", accuracy)\n",
        "        print(\"Precision:\", precision)\n",
        "        print(\"Recall:\", recall)\n",
        "        print(\"F1 Score:\", f1)\n",
        "        print(\"ROC AUC:\", roc_auc)\n",
        "    else:\n",
        "        best_model.fit(X_train, y_train)\n",
        "        y_pred = best_model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average='weighted',zero_division=1)\n",
        "        recall = recall_score(y_test, y_pred, average='weighted')\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        roc_auc = roc_auc_score(y_test, y_pred, average='weighted', multi_class='ovr')\n",
        "        print(f\"Evaluation Metrics {model_name}:\")\n",
        "        print(\"Accuracy:\", accuracy)\n",
        "        print(\"Precision:\", precision)\n",
        "        print(\"Recall:\", recall)\n",
        "        print(\"F1 Score:\", f1)\n",
        "        print(\"ROC AUC:\", roc_auc)\n",
        "    print(f\"{model_name} - Best Parameters: {best_params}, Accuracy: {accuracy}\")"
      ]
    }
  ]
}